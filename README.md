ğŸ“˜ LIA - Libras com InteligÃªncia Artificial

O LIA Ã© um aplicativo interativo que ensina LÃ­ngua Brasileira de Sinais (Libras) utilizando reconhecimento de gestos em tempo real.
Ele combina MediaPipe, OpenCV, TensorFlow e Tkinter para capturar gestos com a cÃ¢mera, reconhecer sinais e gamificar o aprendizado em nÃ­veis e seÃ§Ãµes temÃ¡ticas.

ğŸš€ Funcionalidades

ğŸ® Aplicativo interativo em interface grÃ¡fica (Tkinter).

âœ‹ Reconhecimento de gestos usando MediaPipe + LSTM.

ğŸ“· Captura de gestos com a cÃ¢mera.

ğŸ“ Coleta de novos gestos e armazenamento em CSV.

ğŸ¤– Treinamento de modelos de reconhecimento personalizados.

ğŸ“Š Feedback em tempo real com confianÃ§a e suavizaÃ§Ã£o de prediÃ§Ãµes.


âš™ï¸ InstalaÃ§Ã£o

Clone este repositÃ³rio:

git clone https://github.com/ElaineFesa/Projeto_Simac.git

Instale as dependÃªncias:

Python 3.11

TensorFlow 2.19.0

MediaPipe 0.10.21

OpenCV

Tkinter (incluso no Python)

NumPy, Pandas, Scikit-learn, Joblib

â–¶ï¸ Como Usar
1. Coletar novos gestos

Execute:

python coletar_gestos.py


Digite o nome do gesto.

Mostre o gesto para a cÃ¢mera.

Pressione EspaÃ§o para gravar (mÃ­nimo 10 frames).

Pressione ESC para cancelar.

Os dados serÃ£o salvos em dados/gestos_libras.csv.

2. Treinar o modelo
python treinar_modelo_gestos.py


Treina um modelo LSTM baseado nos gestos coletados.

Gera os arquivos:

modelos/modelo_gestos.h5 (rede neural treinada).

modelos/rotulador_gestos.pkl (rÃ³tulos dos gestos).

3. Testar reconhecimento
python reconhecer_gestos.py


Inicia a captura da cÃ¢mera.

Exibe os gestos reconhecidos em tempo real.

4. Rodar o aplicativo
python main.py


Interface grÃ¡fica abre em tela cheia.

Escolha a seÃ§Ã£o.

Complete os nÃ­veis mostrando os gestos corretos para a cÃ¢mera.

Avance desbloqueando novas seÃ§Ãµes.

ğŸ‘©â€ğŸ’» Autoria

Desenvolvido por ElaÃ­ne Gomes e Joyce da Costa, 2025.
Projeto acadÃªmico para o SIMAC.
